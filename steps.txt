Open Anaconda CMD Prompt

Change path to project folder path
    Ex=> cd H:\Projects\ML_Project -> H:

Enter "code ." to Open VS code editor in the specified path

Create a virtual environment using cmd "conda create -p venv python==3.8 -y" 

Activate environment using "conda activate venv/" notice the (base) goes off

Intialize git repo "git init"

Create "README.md" file
    Add README file to git repo "git add README.md"

Commit changes "git commit -m "first commit""

Use "git status" to check the list the files from repo

Do branching using "git branch -M main" 

Add the origin "git remote add origin https://github.com/aniket199719/ML-Project.git"

Check the sync using "git remote -v"

To push data into git repo "git push -u origin main" 
    NOTE: If doing push for the first time you will have to set "git global"using below cmds
        $ git config --global user.name "John Doe"
        $ git config --global user.email johndoe@example.com

Create ".gitignore" file by choose python for the same file

"__init__.py" is a file which can be used as a package and can be imported

Create "setup.py" file i.e., is resposible in creating ML application as a package and deploy it

Components are the modules which we are going to use in creating the project

In "exception.py" import sys package (The sys module in Python provides various functions and variables that are used to manipulate different parts of the Python runtime environment. It allows operating on the interpreter as it provides access to the variables and functions that interact strongly with the interpreter.)

Go through once documentation of logger and exception handling

CMD'S Summary:
git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/aniket199719/ML-Project.git
git remote -v
git push -u origin main

git add .
git status
git commit -m "desired commit name"
git push -u origin main

============================== DOCKER ================================

- Containers are combination of layers of images w.r.t dependencies, where each layer of image can be python, mongodb, mysql, anaconda, Linux etc,.

- When all the layers of images are combined together, they are called as docker image (or package).

- When we run docker image it creates a container with all the dependencies installed referred as environment.

- Docker image size usually smaller as compared to VM image size.

- Dockers containers start and run much faster as they do not have their own OS kernel, whereas VM is slower since they have there own OS kernel

- Compatibility issues in VM image does not exist, bur it exist for docker image.

- When "host = 0.0.0.0" means we can access docker_image using localhost ip_address or using local ip_address.

- Format of dockerfile (should be created in VS code named as "Dockerfile"):

	FROM python:3.8-alpine
	COPY . .
	WORKDIR /app
	ENV FLASK_APP = appy.py
	ENV FLASK_RUN_HOST = 0.0.0.0
	RUN pip install -r requirements.txt
	EXPOSE 5000
	CMD ["flask", "run"]

- Docker CMD's to create, view, push, pull, remove, rename and run the docker_image:

	- For Login: "docker login" (type username press enter and then type password)

	- View the images in docker: "docker images"

	- Building the docker_image: "docker build -t username/docker_image_name ."

	- Removing the docker image/app: "docker image rm -f docker_image_name:tagname" 

	- Renaming the existing docker image: "docker tag username/docker_image_name username/docker_image_new_name" 

	- Push the docker image from local system to docker hub: "docker push username/docker_image_name:tagname" 

	- Pull the docker image from docker hub to local system: "docker pull username/docker_image_name:tagname" 

	- Run the docker image on local system: "docker run -p 5000:5000 username/docker_image_name:tagname" (5000 represents port number)

	- Run the docker image on local system in detach mode: "docker run -d -p 5000:5000 username/docker_image_name:tagname" (5000 represents port number)

- Docker Compose: Is a tool for defining and running multi-container docker applications, in order to make this run and to interact each other we will need two files i.e., "docker-compose.yml" and "dockerfile". 
 
 	- Format for "dockerfile":

 		FROM python:3.8-alpine
		COPY . .
		WORKDIR /app
		ENV FLASK_APP = appy.py
		ENV FLASK_RUN_HOST = 0.0.0.0
		RUN pip install -r requirements.txt
		EXPOSE 5000
		CMD ["flask", "run"]

	- Format for "docker-compose.yml" containing 2 images (follow the indentation):

		version: "3.0"
		services:
			web:
				image: web-app   #name of image
				build: .
				ports:
					- "5000:5000"
				redis:
					image:redis  #name of image

======================================= AWS Deployment =======================================

- AWS Elastic Container Registry (ECR): It is a container registry used to store private docker images. 